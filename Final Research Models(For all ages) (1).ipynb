{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe8554b-6f9d-4ee2-ae2c-7dc3636b4114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OrdinalEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb7444e6-7e5f-40ba-adc7-6e4590aebb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data = pd.read_csv('dataset.csv')\n",
    "data['BPM'] = data['BPM'].round(2)\n",
    "\n",
    "# Apply Label Encoding\n",
    "label_cols = ['While working', 'Instrumentalist', 'Composer', 'Exploratory', 'Foreign languages', 'Fav genre']\n",
    "data[label_cols] = data[label_cols].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# Define the frequency and effect order\n",
    "frequency_order = ['Never', 'Rarely', 'Sometimes', 'Very frequently']\n",
    "effect_order = ['Worsen', 'No effect', 'Improve']\n",
    "\n",
    "# Apply Ordinal Encoding\n",
    "encoder1 = OrdinalEncoder(categories=[frequency_order] * 16)\n",
    "encoder2 = OrdinalEncoder(categories=[effect_order])\n",
    "freq_cols = [\n",
    "    'Frequency [Classical]', 'Frequency [Country]', 'Frequency [EDM]', 'Frequency [Folk]', \n",
    "    'Frequency [Gospel]', 'Frequency [Hip hop]', 'Frequency [Jazz]', 'Frequency [K pop]', \n",
    "    'Frequency [Latin]', 'Frequency [Lofi]', 'Frequency [Metal]', 'Frequency [Pop]', \n",
    "    'Frequency [R&B]', 'Frequency [Rap]', 'Frequency [Rock]', 'Frequency [Video game music]'\n",
    "]\n",
    "data[freq_cols] = encoder1.fit_transform(data[freq_cols])\n",
    "data[['Music effects']] = encoder2.fit_transform(data[['Music effects']])\n",
    "\n",
    "# Define features and target\n",
    "X = np.array(data.drop('Music effects', axis=1))\n",
    "y = np.array(data['Music effects'])\n",
    "\n",
    "# SMOTE to handle class imbalance\n",
    "sampling_strategy = {0: 500, 1: 500, 2: 600}\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
    "X, y = smote.fit_resample(X, y)\n",
    "\n",
    "# Initialize K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7669dece-a013-452e-91e2-a938e8d23e39",
   "metadata": {},
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce2ed2c3-624f-4011-b998-08844ae34e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n",
      "Best Parameters: {'class_weight': 'balanced', 'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "# Feature selection with SelectFromModel\n",
    "selector = SelectFromModel(ExtraTreesClassifier(n_estimators=100, random_state=42))\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "rf_model = RandomForestClassifier(random_state=42, oob_score=True)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [6, 8, 10, 12],\n",
    "    'min_samples_split': [10, 15, 20],\n",
    "    'min_samples_leaf': [5, 10, 15],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_selected, y)\n",
    "\n",
    "# Get the best model and evaluate\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "774fbd84-bc62-4237-bf5c-9229eac41d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.8469\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.97        93\n",
      "         1.0       0.80      0.67      0.73        96\n",
      "         2.0       0.80      0.88      0.84       131\n",
      "\n",
      "    accuracy                           0.85       320\n",
      "   macro avg       0.85      0.84      0.85       320\n",
      "weighted avg       0.85      0.85      0.84       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[ 92   0   1]\n",
      " [  4  64  28]\n",
      " [  0  16 115]]\n",
      "\n",
      "Test Accuracy: 0.8656\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.97      0.92        87\n",
      "         1.0       0.87      0.74      0.80       105\n",
      "         2.0       0.85      0.90      0.87       128\n",
      "\n",
      "    accuracy                           0.87       320\n",
      "   macro avg       0.87      0.87      0.87       320\n",
      "weighted avg       0.87      0.87      0.86       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[ 84   1   2]\n",
      " [  9  78  18]\n",
      " [  2  11 115]]\n",
      "\n",
      "Test Accuracy: 0.8750\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96       107\n",
      "         1.0       0.84      0.74      0.79        93\n",
      "         2.0       0.83      0.90      0.86       120\n",
      "\n",
      "    accuracy                           0.88       320\n",
      "   macro avg       0.88      0.87      0.87       320\n",
      "weighted avg       0.87      0.88      0.87       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[103   1   3]\n",
      " [  5  69  19]\n",
      " [  0  12 108]]\n",
      "\n",
      "Test Accuracy: 0.8500\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97       114\n",
      "         1.0       0.76      0.68      0.72        82\n",
      "         2.0       0.80      0.85      0.82       124\n",
      "\n",
      "    accuracy                           0.85       320\n",
      "   macro avg       0.84      0.83      0.84       320\n",
      "weighted avg       0.85      0.85      0.85       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[111   0   3]\n",
      " [  2  56  24]\n",
      " [  1  18 105]]\n",
      "\n",
      "Test Accuracy: 0.8125\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95        99\n",
      "         1.0       0.85      0.64      0.73       124\n",
      "         2.0       0.69      0.85      0.76        97\n",
      "\n",
      "    accuracy                           0.81       320\n",
      "   macro avg       0.82      0.83      0.81       320\n",
      "weighted avg       0.82      0.81      0.81       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[99  0  0]\n",
      " [ 9 79 36]\n",
      " [ 1 14 82]]\n",
      "Average Confusion Matrix:\n",
      "[[ 97.8   0.4   1.8]\n",
      " [  5.8  69.2  25. ]\n",
      " [  0.8  14.2 105. ]]\n",
      "\n",
      "Average Training Accuracy: 0.9467\n",
      "Average Test Accuracy: 0.8500\n",
      "OOB Accuracy: 0.8438\n"
     ]
    }
   ],
   "source": [
    "# Perform K-Fold Cross-Validation with the best model\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "confusion_matrices = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    best_rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on the train set\n",
    "    train_pred = best_rf_model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    # Evaluate on the test set\n",
    "    y_pred = best_rf_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    \n",
    "    # Classification report and confusion matrix\n",
    "    print(f'\\nTest Accuracy: {test_accuracy:.4f}')\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "    confusion_matrices.append(cm)\n",
    "    print(f'Confusion Matrix for this Fold:\\n{cm}')\n",
    "\n",
    "# Calculate the average confusion matrix\n",
    "avg_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "print(f'Average Confusion Matrix:\\n{avg_confusion_matrix}')\n",
    "\n",
    "# Calculate average train and test accuracy\n",
    "avg_train_accuracy = np.mean(train_accuracies)\n",
    "avg_test_accuracy = np.mean(test_accuracies)\n",
    "print(f'\\nAverage Training Accuracy: {avg_train_accuracy:.4f}')\n",
    "print(f'Average Test Accuracy: {avg_test_accuracy:.4f}')\n",
    "\n",
    "# Out-of-Bag (OOB) score\n",
    "oob_score = best_rf_model.oob_score_\n",
    "print(f'OOB Accuracy: {oob_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf5aec6-266f-4388-9209-b5cf5422a2ce",
   "metadata": {},
   "source": [
    "#SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96efa3da-234c-4735-aeaa-44be0dd23c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best Parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Feature selection with Recursive Feature Elimination (RFE)\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "selector = RFE(estimator=svm_model, n_features_to_select=10, step=1)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV for SVM\n",
    "svm_model = SVC(probability=True, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'gamma': ['scale'],\n",
    "    'kernel': ['linear', 'rbf'],  # Removed 'poly' for simplicity\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_selected, y)\n",
    "\n",
    "# Get the best model and evaluate\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caf58005-a136-4ad0-9095-626e7f11edbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.79375  0.79375  0.85625  0.809375 0.775   ]\n",
      "Mean Cross-Validation Score: 0.8056\n",
      "\n",
      "Fold Test Accuracy: 0.7937\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97        93\n",
      "         1.0       0.65      0.71      0.68        96\n",
      "         2.0       0.79      0.71      0.75       131\n",
      "\n",
      "    accuracy                           0.79       320\n",
      "   macro avg       0.80      0.81      0.80       320\n",
      "weighted avg       0.79      0.79      0.79       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[93  0  0]\n",
      " [ 4 68 24]\n",
      " [ 2 36 93]]\n",
      "\n",
      "Fold Test Accuracy: 0.7937\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95        87\n",
      "         1.0       0.72      0.75      0.73       105\n",
      "         2.0       0.78      0.69      0.73       128\n",
      "\n",
      "    accuracy                           0.79       320\n",
      "   macro avg       0.80      0.81      0.80       320\n",
      "weighted avg       0.79      0.79      0.79       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[87  0  0]\n",
      " [ 1 79 25]\n",
      " [ 9 31 88]]\n",
      "\n",
      "Fold Test Accuracy: 0.8562\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.96       107\n",
      "         1.0       0.78      0.80      0.79        93\n",
      "         2.0       0.85      0.78      0.81       120\n",
      "\n",
      "    accuracy                           0.86       320\n",
      "   macro avg       0.85      0.86      0.85       320\n",
      "weighted avg       0.85      0.86      0.85       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[107   0   0]\n",
      " [  2  74  17]\n",
      " [  6  21  93]]\n",
      "\n",
      "Fold Test Accuracy: 0.8094\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98       114\n",
      "         1.0       0.62      0.72      0.67        82\n",
      "         2.0       0.80      0.69      0.74       124\n",
      "\n",
      "    accuracy                           0.81       320\n",
      "   macro avg       0.80      0.80      0.80       320\n",
      "weighted avg       0.81      0.81      0.81       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[114   0   0]\n",
      " [  2  59  21]\n",
      " [  2  36  86]]\n",
      "\n",
      "Fold Test Accuracy: 0.7750\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95        99\n",
      "         1.0       0.76      0.65      0.70       124\n",
      "         2.0       0.65      0.71      0.68        97\n",
      "\n",
      "    accuracy                           0.78       320\n",
      "   macro avg       0.77      0.79      0.78       320\n",
      "weighted avg       0.77      0.78      0.77       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[99  0  0]\n",
      " [ 7 80 37]\n",
      " [ 3 25 69]]\n",
      "Average Confusion Matrix:\n",
      "[[100.    0.    0. ]\n",
      " [  3.2  72.   24.8]\n",
      " [  4.4  29.8  85.8]]\n",
      "Average Train Accuracy: 0.9356\n",
      "Average Test Accuracy: 0.8056\n"
     ]
    }
   ],
   "source": [
    "# Perform K-Fold Cross-Validation with the best model\n",
    "scores = cross_val_score(best_svm_model, X_selected, y, cv=kf, scoring='accuracy')\n",
    "print(f'Cross-Validation Scores: {scores}')\n",
    "print(f'Mean Cross-Validation Score: {scores.mean():.4f}')\n",
    "\n",
    "\n",
    "confusion_matrices = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    best_svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = best_svm_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    train_accuracy = best_svm_model.score(X_train, y_train)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    \n",
    "    print(f'\\nFold Test Accuracy: {test_accuracy:.4f}')\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Compute confusion matrix for this fold\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "    confusion_matrices.append(cm)\n",
    "    print(f'Confusion Matrix for this Fold:\\n{cm}')\n",
    "\n",
    "# Calculate the average confusion matrix\n",
    "avg_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "print(f'Average Confusion Matrix:\\n{avg_confusion_matrix}')\n",
    "\n",
    "# Calculate average train and test accuracies\n",
    "avg_train_accuracy = np.mean(train_accuracies)\n",
    "avg_test_accuracy = np.mean(test_accuracies)\n",
    "print(f'Average Train Accuracy: {avg_train_accuracy:.4f}')\n",
    "print(f'Average Test Accuracy: {avg_test_accuracy:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c5493-75a0-4629-b22e-dbd71bcf83cc",
   "metadata": {},
   "source": [
    "#Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e179046-3a4d-4e64-8466-9ebb144d6274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Parameters: {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Feature selection with Recursive Feature Elimination (RFE)\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "selector = RFE(estimator=logistic_model, n_features_to_select=10, step=1)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV for Logistic Regression\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['liblinear'], \n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=logistic_model, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_selected, y)\n",
    "\n",
    "# Get the best model and evaluate\n",
    "best_logistic_model = grid_search.best_estimator_\n",
    "print(f'Best Parameters: {grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceb18b14-8b3c-4772-aec2-1abe41972475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.66875  0.6375   0.646875 0.69375  0.60625 ]\n",
      "Mean Cross-Validation Score: 0.6506\n",
      "\n",
      "Test Accuracy: 0.6687\n",
      "Training Accuracy: 0.6641\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.91      0.81        93\n",
      "         1.0       0.52      0.44      0.47        96\n",
      "         2.0       0.71      0.66      0.69       131\n",
      "\n",
      "    accuracy                           0.67       320\n",
      "   macro avg       0.65      0.67      0.66       320\n",
      "weighted avg       0.66      0.67      0.66       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[85  7  1]\n",
      " [19 42 35]\n",
      " [12 32 87]]\n",
      "\n",
      "Test Accuracy: 0.6375\n",
      "Training Accuracy: 0.6766\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.98      0.80        87\n",
      "         1.0       0.59      0.42      0.49       105\n",
      "         2.0       0.62      0.59      0.60       128\n",
      "\n",
      "    accuracy                           0.64       320\n",
      "   macro avg       0.63      0.66      0.63       320\n",
      "weighted avg       0.63      0.64      0.62       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[85  1  1]\n",
      " [17 44 44]\n",
      " [24 29 75]]\n",
      "\n",
      "Test Accuracy: 0.6469\n",
      "Training Accuracy: 0.6820\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.94      0.81       107\n",
      "         1.0       0.50      0.42      0.46        93\n",
      "         2.0       0.66      0.56      0.61       120\n",
      "\n",
      "    accuracy                           0.65       320\n",
      "   macro avg       0.63      0.64      0.63       320\n",
      "weighted avg       0.63      0.65      0.63       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[101   6   0]\n",
      " [ 20  39  34]\n",
      " [ 20  33  67]]\n",
      "\n",
      "Test Accuracy: 0.6937\n",
      "Training Accuracy: 0.6609\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.92      0.87       114\n",
      "         1.0       0.51      0.52      0.51        82\n",
      "         2.0       0.69      0.60      0.64       124\n",
      "\n",
      "    accuracy                           0.69       320\n",
      "   macro avg       0.67      0.68      0.67       320\n",
      "weighted avg       0.69      0.69      0.69       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[105   9   0]\n",
      " [  5  43  34]\n",
      " [ 17  33  74]]\n",
      "\n",
      "Test Accuracy: 0.6062\n",
      "Training Accuracy: 0.6727\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.91      0.79        99\n",
      "         1.0       0.63      0.35      0.45       124\n",
      "         2.0       0.49      0.62      0.55        97\n",
      "\n",
      "    accuracy                           0.61       320\n",
      "   macro avg       0.61      0.63      0.60       320\n",
      "weighted avg       0.61      0.61      0.59       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[90  4  5]\n",
      " [23 44 57]\n",
      " [15 22 60]]\n",
      "Average Confusion Matrix:\n",
      "[[93.2  5.4  1.4]\n",
      " [16.8 42.4 40.8]\n",
      " [17.6 29.8 72.6]]\n",
      "\n",
      "Average Training Accuracy: 0.6713\n",
      "Average Test Accuracy: 0.6506\n"
     ]
    }
   ],
   "source": [
    "# Perform K-Fold Cross-Validation with the best model\n",
    "scores = cross_val_score(best_logistic_model, X_selected, y, cv=kf, scoring='accuracy')\n",
    "print(f'Cross-Validation Scores: {scores}')\n",
    "print(f'Mean Cross-Validation Score: {scores.mean():.4f}')\n",
    "\n",
    "# List to store confusion matrices and accuracy differences\n",
    "confusion_matrices = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    best_logistic_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = best_logistic_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    train_accuracy = accuracy_score(y_train, best_logistic_model.predict(X_train))\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    print(f'\\nTest Accuracy: {test_accuracy:.4f}')\n",
    "    print(f'Training Accuracy: {train_accuracy:.4f}')\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Compute confusion matrix for this fold\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "    confusion_matrices.append(cm)\n",
    "    print(f'Confusion Matrix for this Fold:\\n{cm}')\n",
    "\n",
    "# Calculate the average confusion matrix\n",
    "avg_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "print(f\"Average Confusion Matrix:\\n{avg_confusion_matrix}\")\n",
    "\n",
    "# Check for overfitting using average training and test accuracies\n",
    "avg_train_accuracy = np.mean(train_accuracies)\n",
    "avg_test_accuracy = np.mean(test_accuracies)\n",
    "print(f'\\nAverage Training Accuracy: {avg_train_accuracy:.4f}')\n",
    "print(f'Average Test Accuracy: {avg_test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31e20b4-205e-4549-bf2c-a088a4261e0d",
   "metadata": {},
   "source": [
    "#KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c9e2471-f47d-4764-90d0-2113a06a242b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Feature selection with Recursive Feature Elimination (RFE) using ExtraTreesClassifier\n",
    "selector = RFE(estimator=ExtraTreesClassifier(n_estimators=100, random_state=42), n_features_to_select=10, step=1)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV for KNN\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_selected, y)\n",
    "\n",
    "# Get the best model and evaluate\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60c3af3a-857d-42fd-9b73-bfc226cf557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.8375   0.83125  0.85625  0.846875 0.8375  ]\n",
      "Mean Cross-Validation Score: 0.8419\n",
      "\n",
      "Accuracy: 0.8375\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96        93\n",
      "         1.0       0.74      0.79      0.76        96\n",
      "         2.0       0.85      0.76      0.80       131\n",
      "\n",
      "    accuracy                           0.84       320\n",
      "   macro avg       0.84      0.85      0.84       320\n",
      "weighted avg       0.84      0.84      0.84       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[93  0  0]\n",
      " [ 3 76 17]\n",
      " [ 5 27 99]]\n",
      "\n",
      "Accuracy: 0.8313\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      1.00      0.94        87\n",
      "         1.0       0.76      0.84      0.80       105\n",
      "         2.0       0.87      0.71      0.78       128\n",
      "\n",
      "    accuracy                           0.83       320\n",
      "   macro avg       0.83      0.85      0.84       320\n",
      "weighted avg       0.83      0.83      0.83       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[87  0  0]\n",
      " [ 3 88 14]\n",
      " [ 9 28 91]]\n",
      "\n",
      "Accuracy: 0.8562\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.96       107\n",
      "         1.0       0.76      0.84      0.80        93\n",
      "         2.0       0.86      0.74      0.80       120\n",
      "\n",
      "    accuracy                           0.86       320\n",
      "   macro avg       0.85      0.86      0.85       320\n",
      "weighted avg       0.86      0.86      0.85       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[107   0   0]\n",
      " [  1  78  14]\n",
      " [  7  24  89]]\n",
      "\n",
      "Accuracy: 0.8469\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.99      0.95       114\n",
      "         1.0       0.75      0.79      0.77        82\n",
      "         2.0       0.86      0.75      0.80       124\n",
      "\n",
      "    accuracy                           0.85       320\n",
      "   macro avg       0.84      0.84      0.84       320\n",
      "weighted avg       0.85      0.85      0.84       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[113   0   1]\n",
      " [  3  65  14]\n",
      " [  9  22  93]]\n",
      "\n",
      "Accuracy: 0.8375\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95        99\n",
      "         1.0       0.80      0.83      0.82       124\n",
      "         2.0       0.80      0.68      0.73        97\n",
      "\n",
      "    accuracy                           0.84       320\n",
      "   macro avg       0.84      0.84      0.83       320\n",
      "weighted avg       0.83      0.84      0.83       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[ 99   0   0]\n",
      " [  4 103  17]\n",
      " [  6  25  66]]\n",
      "Average Confusion Matrix:\n",
      "[[99.8  0.   0.2]\n",
      " [ 2.8 82.  15.2]\n",
      " [ 7.2 25.2 87.6]]\n",
      "\n",
      "Average Test Accuracy: 0.8419\n"
     ]
    }
   ],
   "source": [
    "# Perform K-Fold Cross-Validation with the best model\n",
    "scores = cross_val_score(best_knn_model, X_selected, y, cv=kf, scoring='accuracy')\n",
    "print(f'Cross-Validation Scores: {scores}')\n",
    "print(f'Mean Cross-Validation Score: {scores.mean():.4f}')\n",
    "\n",
    "# List to store confusion matrices and accuracies for each fold\n",
    "confusion_matrices = []\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    best_knn_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = best_knn_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'\\nAccuracy: {accuracy:.4f}')\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Compute confusion matrix for this fold\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "    confusion_matrices.append(cm)\n",
    "    print(f'Confusion Matrix for this Fold:\\n{cm}')\n",
    "\n",
    "# Calculate the average confusion matrix\n",
    "avg_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "print(f'Average Confusion Matrix:\\n{avg_confusion_matrix}')\n",
    "\n",
    "avg_train_accuracy = np.mean(accuracies)\n",
    "print(f'\\nAverage Test Accuracy: {avg_train_accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7b7ca-0a19-4f36-90c3-2fc7cc7ec60e",
   "metadata": {},
   "source": [
    "#Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab55bb7c-3db8-42fd-8ac4-eb27a462d861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Feature selection with Recursive Feature Elimination (RFE)\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "selector = RFE(estimator=dt_model, n_features_to_select=10, step=1)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV for Decision Tree\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_selected, y)\n",
    "\n",
    "# Get the best model and evaluate\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a90f40-97e4-4c12-a743-f5518458e3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.746875 0.815625 0.759375 0.79375  0.70625 ]\n",
      "Mean Cross-Validation Score: 0.7644\n",
      "\n",
      "Test Accuracy: 0.7469\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.92      0.90        93\n",
      "         1.0       0.64      0.64      0.64        96\n",
      "         2.0       0.72      0.70      0.71       131\n",
      "\n",
      "    accuracy                           0.75       320\n",
      "   macro avg       0.75      0.75      0.75       320\n",
      "weighted avg       0.74      0.75      0.75       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[86  1  6]\n",
      " [ 6 61 29]\n",
      " [ 6 33 92]]\n",
      "\n",
      "Test Accuracy: 0.8156\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.92      0.91        87\n",
      "         1.0       0.82      0.68      0.74       105\n",
      "         2.0       0.76      0.86      0.81       128\n",
      "\n",
      "    accuracy                           0.82       320\n",
      "   macro avg       0.83      0.82      0.82       320\n",
      "weighted avg       0.82      0.82      0.81       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[ 80   3   4]\n",
      " [  3  71  31]\n",
      " [  5  13 110]]\n",
      "\n",
      "Test Accuracy: 0.7594\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.88      0.88       107\n",
      "         1.0       0.68      0.63      0.66        93\n",
      "         2.0       0.71      0.75      0.73       120\n",
      "\n",
      "    accuracy                           0.76       320\n",
      "   macro avg       0.76      0.75      0.76       320\n",
      "weighted avg       0.76      0.76      0.76       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[94  6  7]\n",
      " [ 4 59 30]\n",
      " [ 8 22 90]]\n",
      "\n",
      "Test Accuracy: 0.7937\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.92       114\n",
      "         1.0       0.70      0.65      0.67        82\n",
      "         2.0       0.75      0.76      0.75       124\n",
      "\n",
      "    accuracy                           0.79       320\n",
      "   macro avg       0.78      0.78      0.78       320\n",
      "weighted avg       0.79      0.79      0.79       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[107   3   4]\n",
      " [  1  53  28]\n",
      " [ 10  20  94]]\n",
      "\n",
      "Test Accuracy: 0.7063\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.91      0.85        99\n",
      "         1.0       0.76      0.52      0.62       124\n",
      "         2.0       0.58      0.73      0.65        97\n",
      "\n",
      "    accuracy                           0.71       320\n",
      "   macro avg       0.72      0.72      0.71       320\n",
      "weighted avg       0.72      0.71      0.70       320\n",
      "\n",
      "Confusion Matrix for this Fold:\n",
      "[[90  1  8]\n",
      " [15 65 44]\n",
      " [ 7 19 71]]\n",
      "Average Confusion Matrix:\n",
      "[[91.4  2.8  5.8]\n",
      " [ 5.8 61.8 32.4]\n",
      " [ 7.2 21.4 91.4]]\n",
      "\n",
      "Average Training Accuracy: 0.8794\n",
      "Average Test Accuracy: 0.7644\n"
     ]
    }
   ],
   "source": [
    "# Perform K-Fold Cross-Validation with the best model\n",
    "scores = cross_val_score(best_dt_model, X_selected, y, cv=kf, scoring='accuracy')\n",
    "print(f'Cross-Validation Scores: {scores}')\n",
    "print(f'Mean Cross-Validation Score: {scores.mean():.4f}')\n",
    "\n",
    "# List to store confusion matrices and training accuracies for overfitting check\n",
    "confusion_matrices = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_selected):\n",
    "    X_train, X_test = X_selected[train_index], X_selected[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    best_dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = best_dt_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    \n",
    "    # Evaluate the model on the training set\n",
    "    y_train_pred = best_dt_model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    print(f'\\nTest Accuracy: {test_accuracy:.4f}')\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Compute confusion matrix for this fold\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "    confusion_matrices.append(cm)\n",
    "    print(f'Confusion Matrix for this Fold:\\n{cm}')\n",
    "\n",
    "# Calculate the average confusion matrix\n",
    "avg_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "print(f'Average Confusion Matrix:\\n{avg_confusion_matrix}')\n",
    "\n",
    "# Calculate average training and test accuracy across all folds\n",
    "avg_train_accuracy = np.mean(train_accuracies)\n",
    "avg_test_accuracy = np.mean(test_accuracies)\n",
    "\n",
    "print(f'\\nAverage Training Accuracy: {avg_train_accuracy:.4f}')\n",
    "print(f'Average Test Accuracy: {avg_test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236e7084-e006-45d1-9218-14e325578a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
